{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## PART 4 : CNN Implementation using Pytorch and experiments. "
      ],
      "metadata": {
        "id": "7-30AIVlOecf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ux5i51l6v0JA"
      },
      "outputs": [],
      "source": [
        "import torch as torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import torchvision\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR_NN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(CIFAR_NN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3) # kernel size can be an int (for sqaure kernels) or tuple (generic)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        # is reshape layer explicitly needed ??? \n",
        "        self.fc1 = nn.Linear(576, 64) \n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "        self.softmax= nn.Softmax()\n",
        "\n",
        "        ## softmax activation after fc2 for faster convergence\n",
        "    \n",
        "    def forward(self, x):\n",
        "      \n",
        "         y = self.conv1(x)\n",
        "         y = self.relu1(y)\n",
        "         y = self.pool1(y)\n",
        "         y = self.conv2(y)\n",
        "         y = self.relu2(y)\n",
        "         y = self.pool2(y)\n",
        "         y = self.conv3(y)        \n",
        "         y = self.relu3(y)\n",
        "         y=  torch.reshape(y,(-1,576))                     \n",
        "         y = self.fc1(y)\n",
        "         y = self.relu4(y)\n",
        "         y = self.fc2(y)    \n",
        "        #  y = self.softmax(y)\n",
        "        \n",
        "         return y\n",
        "      \n",
        "    "
      ],
      "metadata": {
        "id": "TMBj7On-wQ5j"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For cifar-10 you get pre-built loaders\n",
        "transforms = T.Compose([T.ToTensor(), T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "# transforms = T.Compose([T.ToTensor()])\n",
        "\n",
        "traindata = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transforms,download=True)\n",
        "trainloader = torch.utils.data.DataLoader(traindata, batch_size=32, shuffle=True, num_workers=4)\n",
        "trainloader2 = torch.utils.data.DataLoader(traindata, batch_size=32, shuffle=True, num_workers=4)\n",
        "\n",
        "valdata = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transforms)\n",
        "valloader = torch.utils.data.DataLoader(valdata, batch_size=32, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo3vTnI_B4gS",
        "outputId": "c4db7510-5459-4afb-ed60-c82820aa5b60"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_plot_num=10"
      ],
      "metadata": {
        "id": "IdHuz_uEJrmy"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrArray=[0.001,0.01,0.0003,0.0001]\n",
        "batchArray=[4,8,16,32]"
      ],
      "metadata": {
        "id": "DP6E3Z2w-X1a"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Components: model, loss, optimizer, data loader\n",
        "\n",
        "## Data loader is a generator --> (X, y) pairs for your dataset --> batch size x (image tensor, label tensor)\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from torch.optim.lr_scheduler import * # Import your choice of scheduler here\n",
        "epArray=[13]\n",
        "for epoch_num in epArray:        \n",
        "    class_accuracies=[]\n",
        "    model = CIFAR_NN()\n",
        "    ## Signature might not be accurate \n",
        "    ## selectively train different layers, and freeze others\n",
        "    #for param in model.parameters:\n",
        "    #    param.requires_grad = False\n",
        "    #model.fc1.requires_grad = True\n",
        "    LEARNING_RATE=0.001\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss() # change this for other losses\n",
        "    optimizer = optim.Adam(model.parameters(),lr= LEARNING_RATE)\n",
        "    # optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE , momentum=0.9)\n",
        "    scheduler = CosineAnnealingLR(optimizer,T_max = 32, eta_min = 1e-6) # Multiplicative factor of learning rate decay\n",
        "\n",
        "\n",
        "    # scheduler = ExponentialLR(optimizer,gamma=0.95) # Multiplicative factor of learning rate decay\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    epochs = epoch_num\n",
        "    model.to(device)\n",
        "    trainlosses=[]\n",
        "    vallosses=[]\n",
        "    val_accuracies=[]\n",
        "    epoch_loss_array=[]\n",
        "    train_accuracies=[]\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        iter=0\n",
        "        for images, labels in trainloader:\n",
        "            iter+=1\n",
        "            # print(images.shape)\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            if((iter%500)==0):\n",
        "                total_correct=0\n",
        "                total_samples=0\n",
        "                for ims, lbs in trainloader2:\n",
        "                  ims = ims.to(device)\n",
        "                  lbs = lbs.to(device)\n",
        "\n",
        "                  outputs_train = model(ims)\n",
        "                  _, predicted_train = torch.max(outputs_train, dim=1)\n",
        "\n",
        "                  total_correct += torch.sum(predicted_train == lbs).item()\n",
        "                  total_samples += lbs.size(0)\n",
        "                train_accuracies.append(total_correct / total_samples)\n",
        "\n",
        "                class_correct = {i: 0 for i in range(10)}\n",
        "                class_total = {i: 0 for i in range(10)}\n",
        "                loss_val=0\n",
        "                val_iter=0\n",
        "                for val_images,val_labels in valloader:\n",
        "                  val_iter+=1\n",
        "                  val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
        "                  model_output= model(val_images)\n",
        "                  loss_val += loss_fn(model_output,val_labels).item()\n",
        "                  _, predicted = torch.max(model_output, 1)\n",
        "                  for i in range(val_labels.size(0)):\n",
        "                    label = val_labels[i].item()\n",
        "                    class_correct[label] += (predicted[i] == label).item()\n",
        "                    class_total[label] += 1\n",
        "                # print(\"v \",loss_val/val_iter)\n",
        "                for i in range(10):\n",
        "                  acc = 100.0 * class_correct[i] / class_total[i]\n",
        "                  # print('Accuracy of %5s : %2d %%' % (i, acc))\n",
        "                  class_accuracies.append(acc)\n",
        "                vallosses.append(loss_val/val_iter)\n",
        "                # print(\"val loss is \", loss_val)\n",
        "            \n",
        "            # print(labels.shape,outputs.shape)\n",
        "            \n",
        "            loss = loss_fn( outputs,labels)\n",
        "            if((iter%50)==0):\n",
        "              trainlosses.append(loss.item())\n",
        "              # print(loss.item())\n",
        "            loss.backward()\n",
        "            # print(optimizer.param_groups[0][\"lr\"],loss.item())\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(\"Epoch Level Loss is \",  epoch_loss/iter)  \n",
        "        epoch_loss_array.append(epoch_loss/iter)\n",
        "        # saving the model weights for all epochs\n",
        "        # save_path = \"./toy_model_%s.pth\"%epoch\n",
        "    \n",
        "        # torch.save(model.state_dict(), save_path)\n",
        "    \n",
        "    class_perf=np.array(class_accuracies)\n",
        "    class_perf=class_perf.reshape((-1,10))\n",
        "    class_perf = class_perf[::5]\n",
        "    plt.plot()\n",
        "# Plot all the columns in a single graph\n",
        "    for i in range(class_perf.shape[1]):\n",
        "        plt.plot(class_perf[:, i], label=f\"Column {i+1}\")\n",
        "\n",
        "    # Add a legend and axis labels\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Index\")\n",
        "    plt.ylabel(\"Value\")\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "    plt.plot(train_accuracies)\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Train Accuracy\")\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "    np.savetxt('my_array.txt'+str(global_plot_num), epoch_loss_array)\n",
        "    files.download('my_array.txt'+str(global_plot_num))\n",
        "\n",
        "    # Create some example data\n",
        "    # train_losses = [0.5, 0.4, 0.3, 0.2, 0.1] * 10 # Replace with your train losses\n",
        "    # val_losses = [0.4, 0.3, 0.2, 0.1,0.6] # Replace with your validation losses\n",
        "\n",
        "    marker_size = 2\n",
        "    dpi = 300\n",
        "\n",
        "\n",
        "    # Plot the train losses\n",
        "    plt.plot(range(len(trainlosses)), trainlosses, 'r-', label='Train Loss')\n",
        "\n",
        "    # Plot the validation losses\n",
        "    x_vals = [(i*10+10) for i in range(len(vallosses))] # Scale the x-axis to match the train losses\n",
        "    plt.plot(x_vals, vallosses, 'b-', label='Validation Loss')\n",
        "\n",
        "    # Add a legend and axis labels\n",
        "    plt.legend()\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.rcParams['figure.dpi'] = dpi\n",
        "    # Display the plot\n",
        "    # plt.show()\n",
        "    filename = 'loss_plot'+str(global_plot_num)+'.png'\n",
        "    global_plot_num+=1\n",
        "    plt.show()\n",
        "    plt.savefig(filename)\n",
        "    files.download(filename)\n",
        "    plt.clf()"
      ],
      "metadata": {
        "id": "LFXJ-jjaocJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cmodel = A4Net()\n",
        "# model.load_state_dict(torch.load(save_path)) # pass the model weight path\n",
        "\n",
        "# for images, labels in valloader:\n",
        "#     outputs = model(images)\n",
        "#     # logits/ probabilities (if you use softmax) batch_size x 10 [p1, p2, ... p10]\n",
        "#     _, preds = torch.max(outputs, 1)\n",
        "#     print(\"GT: %s, Pred: %s\"%(labels.tolist(), preds.tolist()))\n",
        "#     # ToDo: for accuracy calculation, track the GT and Predictions\n"
      ],
      "metadata": {
        "id": "D6Z8fetWBvN4"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Create some example data\n",
        "# train_losses = [0.5, 0.4, 0.3, 0.2, 0.1] * 10 # Replace with your train losses\n",
        "# val_losses = [0.4, 0.3, 0.2, 0.1,0.6] # Replace with your validation losses\n",
        "\n",
        "# marker_size = 2\n",
        "# dpi = 300\n",
        "\n",
        "\n",
        "# # Plot the train losses\n",
        "# plt.plot(range(len(train_losses)), train_losses, 'r-', label='Train Loss')\n",
        "\n",
        "# # Plot the validation losses\n",
        "# x_vals = [(i*10+10) for i in range(len(val_losses))] # Scale the x-axis to match the train losses\n",
        "# plt.plot(x_vals, val_losses, 'b-', label='Validation Loss')\n",
        "\n",
        "# # Add a legend and axis labels\n",
        "# plt.legend()\n",
        "# plt.xlabel('Iteration')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.rcParams['figure.dpi'] = dpi\n",
        "# # Display the plot\n",
        "# plt.show()\n",
        "# num=2\n",
        "# filename = 'loss_plot'+str(num)+'.png'\n",
        "# plt.savefig(filename)\n",
        "# files.download(filename)"
      ],
      "metadata": {
        "id": "_USv4m9J88Pl"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}